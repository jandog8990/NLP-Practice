{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.493, 'neu': 0.507, 'pos': 0.0, 'compound': -0.5983}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK Pre-trained sentiment analyzer\n",
    "# Built in pretrained analyzer - VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
    "# VADER best used for social media and short sentences\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# polarity analyzes the pos/neg words in a text\n",
    "sia.polarity_scores(\"NLTK is the fkn shit!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "\n",
      "\n",
      "> True RT @Markfergusonuk: David Cameron says he's hungrier than he was five years ago. So are all of the people reliant on food banks...\n",
      "> False RT @thomasmessenger: For all Tories claiming that Labour overspent and thus caused a global financial crisis, ahem... http//t.co/DkLwCwzhDA\n",
      "> True RT @AlanRoden: Scenario: Lab largest party, minority Govt. SNP opposes policy, Lab won't budge. Cons vote against, but Lab has more MPs. Wh…\n",
      "> False SNP leader faces audience questions: Nicola Sturgeon is grilled about the SNP's role at Westminster by a live ... http//t.co/WbnstcNnLd\n",
      "> False RT @NPickavance: FT backs Tories! Who'd have guessed that FT leader writer Jonathan Ford was photod posing nxt to Boris in Uni club? http:/…\n",
      "> True @derekrootboy @ae_parry So the SNP are going to vote with the Tories against Labour? Interesting.\n",
      "> True Hi BAM ! @BarsAndMelody \n",
      "Can you follow my bestfriend @969Horan696 ? \n",
      "She loves you a lot :) \n",
      "See you in Warsaw &lt;3 \n",
      "Love you &lt;3 x4\n",
      "> True RT @gavtheukip: #FARAGE DID AMAZINGLY WELL EVEN WITH THE #BIAS AUDIENCE. MADE VERY GOOD CLEAR POINTS. UNLIKE #LIBLABCONS\n",
      "> False @2015election BBC and news reporters are shafting the people by not giving Nigel Farage a spot in the audience questioning programme.\n",
      "> True @Raheelk We wish you a pleasant time on-board, Raheel :) #FlyHigh\n"
     ]
    }
   ],
   "source": [
    "# twitter samples \n",
    "import nltk\n",
    "\n",
    "# get list of raw tweets with strings\n",
    "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]\n",
    "print(len(tweets))\n",
    "#tweets[:10]\n",
    "\n",
    "# popularity scores for the tweets\n",
    "from random import shuffle\n",
    "\n",
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "print(\"\\n\")\n",
    "shuffle(tweets)\n",
    "for tweet in tweets[:10]:\n",
    "    print(\">\", is_positive(tweet), tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive/negativie movie reviews - already been classified using VADER\n",
    "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "all_review_ids = positive_review_ids + negative_review_ids\n",
    "\n",
    "# set up VADER to rate individual sentences rather than full reviews\n",
    "# VADER needs raw strings for its rating => you can't use words()\n",
    "# make a list of file IDs that corpus uses to reference individual reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.95% correct\n"
     ]
    }
   ],
   "source": [
    "# redefine is positive to work on an entire review. Obtain specific review\n",
    "# using its file ID and then split it into sentences before rating:\n",
    "from statistics import mean\n",
    "\n",
    "def is_positive(review_id: str) -> bool:\n",
    "    \"\"\"\n",
    "    True if the average of all sentence compound scores is positive\n",
    "    \"\"\"\n",
    "    \n",
    "    # first get the raw text for the entire movie\n",
    "    text = nltk.corpus.movie_reviews.raw(review_id)\n",
    "    scores = [\n",
    "        (sia.polarity_scores(sentence)[\"neg\"] and sia.polarity_scores(sentence)[\"compound\"])\n",
    "        # loop through sentences from tokenization\n",
    "        for sentence in nltk.sent_tokenize(text)\n",
    "    ]\n",
    "    return mean(scores) > 0\n",
    "\n",
    "# shuffle the review ids and find if they are positive\n",
    "shuffle(all_review_ids)\n",
    "correct = 0\n",
    "for review_id in all_review_ids:\n",
    "    if is_positive(review_id):\n",
    "        if review_id in positive_review_ids:\n",
    "            correct += 1\n",
    "    else:\n",
    "        if review_id in negative_review_ids:\n",
    "            correct += 1\n",
    "            \n",
    "print(F\"{correct / len(all_review_ids):.2%} correct\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completely\n",
      "pretty\n"
     ]
    }
   ],
   "source": [
    "# Customizing NLTK's Sentiment Analysis\n",
    "# TRICK - figure out which properties of your dataset are \n",
    "# useful in classifying each piece of data into desired categories\n",
    "\n",
    "# ML - these properties are known as features, which you select.\n",
    "\n",
    "# Selecting useful features - by using predefined categ\n",
    "# in movie_reviews corpus you can create positive/negative words.\n",
    "\n",
    "# Determine which ones occur most frequently across each set.\n",
    "# Begin excluding unwanted words and building initial category groups\n",
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "# corpus names/words\n",
    "corpus_words = nltk.corpus.names.words()\n",
    "\n",
    "# skip unwanted words that don't have letters and are not in the unwated list\n",
    "def skip_unwanted(pos_tuple):\n",
    "    word, tag = pos_tuple\n",
    "    if not word.isalpha() or word in unwanted:\n",
    "        return False\n",
    "    if tag.startswith(\"NN\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# get the POS (Part of Speech) tags from the moview reviews\n",
    "pos_reviews = nltk.corpus.movie_reviews.words(categories=[\"pos\"])\n",
    "neg_reviews = nltk.corpus.movie_reviews.words(categories=[\"neg\"])\n",
    "pos_tags = nltk.pos_tag(pos_reviews)\n",
    "neg_tags = nltk.pos_tag(neg_reviews)\n",
    "\n",
    "# filter out the positive tuples using the skip unwanted func\n",
    "pos_words = [word for word, tag in filter(skip_unwanted, pos_tags)]\n",
    "neg_words = [word for word, tag in filter(skip_unwanted, neg_tags)]\n",
    "print(pos_words[123])\n",
    "print(neg_words[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive fd len before = 15449\n",
      "9511\n",
      "cheaply\n"
     ]
    }
   ],
   "source": [
    "# create frequency distributions for custom feature\n",
    "# begin by finding the the common set of words to remove from distribution\n",
    "positive_fd = nltk.FreqDist(pos_words)\n",
    "negative_fd = nltk.FreqDist(neg_words)\n",
    "print(\"positive fd len before = \" + str(len(positive_fd)))\n",
    "\n",
    "# find the intersection between pos and neg words\n",
    "common_set = set(positive_fd).intersection(negative_fd)\n",
    "print(len(common_set))\n",
    "print(list(common_set)[0])\n",
    "\n",
    "# delete the common words in the lists\n",
    "for word in common_set:\n",
    "    del positive_fd[word]\n",
    "    del negative_fd[word]\n",
    "\n",
    "# unique pos/neg words in each freq dist, the amount of words in each set\n",
    "# can be tweaked in order to determine effect on sentiment analysis\n",
    "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
    "top_100_negative = {word for word, count in negative_fd.most_common(100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a feature to extract from data, words that aren't neg/pos\n",
    "# bigram finders (Eg \"thumbs up!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
